---
title: "Bayesian Linear Regression"
author: "Summer Dahlen, Shijie Geng, Mary Morrow, Kayla Mota"
date: '`r Sys.Date()`'
format:
  revealjs: 
    theme: dark
    transition: slide
    transition-speed: fast
    embed-resources: true
    footer: <a href="https://sat6257-shijiegeng.github.io/STA6257_Bayesian_Linear_Regression/" target="_blank">Bayesian Linear Regression</a>
    scrollable: true
editor: 
  markdown: 
    wrap: 72
---

# Overview {.smaller}

::: columns
::: {.column width="45%"}
-   Introduction
    -   What is Bayesian Linear Regression?
    -   How it works
    -   Benefits of BLR
-   Methods
    -   Regression Analysis Basics
    -   BLR Basics
-   Analysis
    -   Exploration Data Analysis
    -   BLR Analysis
-   Conclusion
:::

::: {.column width="55%"}
![](images/posterior%20curves.png)
:::
:::

# Introduction

## What is Bayesian Linear Regression?

Commonly denoted as "BLR", it is a conditional data analytical method
for understanding the relationship between independent and dependent
variables based on Bayes Theorem while handling uncertainties with
accuracy and interpretability[@walker2007application].

![](images/formula.png)

## How it works {.smaller}

::: panel-tabset
### Overview

::: columns
::: {.column width="45%"}
1.  Predict prior values
2.  Input collected data
3.  Obtain posterior distribution (MCMC Method)
4.  Sensitivity analysis
5.  Skewness and heteroscedasticity check (SSSM)
:::

::: {.column width="55%"}
![](images/image_1-01.png)
:::
:::

::: notes
The posterior distribution is proportional to the prior distribution
multiplied by the likelihood function [@baldwin2017introduction].
:::

### MCMC Method

-   The Markov Chain Monte Carlo (MCMC) method involves simulating
    random draws from the posterior distribution, allowing for
    exploration of the parameter space and estimation of the posterior
    distribution even in complex, high-dimensional models
    [@robert2018accelerating; @rojas2020lose].
-   Confirming the convergence of MCMC chains is important for the
    reliability of the results.
-   Evidence of convergence provides confidence in the validity of the
    samples[@marcotte2018gibbs].

### Inferences

-   After obtaining the posterior results, inferences can be used for
    the prior distribution of the current/next experiment
    [@rubio2016bayesian].
    -   Posterior probabilities are assigned to the spectrum of values
        that parameters can assume.
    -   The more prominent the peak, the more effective it is as an
        estimate because a single value has a higher probability
        compared to other values.
        -   The credibility interval, indicating a 95% range of probable
            parameter estimates, is narrower.
        -   Conversely, when the peak is less pronounced, other
            estimates are also plausible, resulting in a wider
            credibility interval for the 95% range of probable parameter
            estimates [@shetty2013evidence; @gill2002bayesian].

### Sensitivity

-   In BLR, even when utilizing representative or informed priors, it is
    crucial to perform a sensitivity analysis to assess the impact of
    different prior specifications on the posterior results.
-   This aims to ensure that the findings are not dependent on the
    choice of prior [@kruschke2021bayesian].

### SSSM

-   Once the experiment is conducted and the posterior distribution is
    obtained, the next step is to conduct a check on skewness of the
    distributions, as well as heteroscedasticity.
-   Although scale mixtures of normal are often used in regression
    analysis to capture heteroscedasticity and outliers, skew-symmetric
    scale mixtures of normal (SSSM) can capture asymmetry, making it
    more robust to use in BLR [@rubio2016bayesian].
:::

## Benefits of BLR

-   More flexible
    -   Captures all uncertain random variables
    -   Good for small sample sizes
    -   Good for various data types
-   Eliminates need for p-values
    -   Richer information on parameters
    -   Allows for simultaneous single change point detection in a
        multivariate sample

::: notes
-   More flexible statistical model as it captures all uncertain random
    variables [@klauenberg2015tutorial] and is also known to be used for
    experiments that have small sample sizes [@sugiarto2021determining]
    and various data types [@kruschke2010bayesian].

-   Eliminates the need for p-values, which offers richer information on
    parameters, and allows for simultaneous single change point
    detection in a multivariate sample [@seidou2007bayesian].
:::

## Use cases of BLR

::: columns
::: {.column width="50%"}
-   Construction
-   Transportation Engineering
-   Biomedicine ![](images/biomedicine%20(2).gif)
:::

::: {.column width="50%"}
![](images/traffic_flow.jpg)
:::
:::

::: notes
-   An example of using BLR includes determining correction coefficients
    to previously inaccurate concrete mixture formulas to ensure the
    correct use and amount of chemicals to prevent and then predict the
    breakdown of the concrete [@zgheib2019bayesian].

-   Another example of BLR is re-determining traffic-flow rate values
    for vehicles to be able to ensure optimal traffic flow and minimize
    to a safe number of vehicles at intersections, which allows for the
    previous rate values from over 20 years ago to be updated
    [@sugiarto2021determining].

-   BLR can also be used to determine the load and strain a bridge can
    take before it is unsafe to be used [@zhang2022long], and it can be
    helpful to predict genetic values for genomic selection for plants
    and animals to prevent the risk of passing on genes that could cause
    illnesses [@perez2010genomic].
:::

# Methods

## Regression Analysis Basics {.smaller}

::: panel-tabset
### Linear Regression Model

Regression analysis is a statistical method that allows to examine the
relationship between two or more variables of interest. Suppose the
response variable $Y$ is a function of several predictor variables,
$x_{i1}, x_{i2},..., x_{ik}$.

To fit a model:

$$
Y = X \beta + \epsilon     \quad(1)
$$ where:

-   $Y = (y_1, y_2,..., y_n)$ is the n×1 vector of response
-   $X$ is a n×p design matrix, $p = k+1$
-   $\beta = (\beta_0, \beta_1,...., \beta_{k})$is the (k+1)×1 vector of
    parameters
-   $\epsilon = (\epsilon_1, \epsilon_2,...., \epsilon_n)$ the n×1
    vector of errors, $\epsilon$ \~ $N_n(0, \sigma^2I)$

### Likelihood Function

The likelihood function of $y$ given $\beta$ and $\sigma^2$ is defined
as follows

$$
f(Y_i = y_i|x, \beta, \sigma^2) = f_y(y|x,\beta,\sigma^2) = (2\pi\sigma^2)^{-\frac{n}{2}} exp^{-\frac{1}{2\sigma^2}(y-x\beta)^T(y-x\beta)}  \quad(2)
$$ which describes the probability of observing the data $y$ given the
predictors $x$ and the parameters $\beta$ and $\sigma^2$.

To make an inference, the $\beta$ parameters are determined through
maximizing the likelihood function.
:::

## BLR Basics {.smaller}

::: panel-tabset
### Normal Distribution

BLR is approached through probability distributions. Instead of
estimating the response variable, y, as a single value, it's drawn from
a probability distribution. When using BLR, the model assumes that the
response follows a normal distribution, expressed as

$$
y \sim N(\beta^TX, \sigma^2I)  \quad(3)
$$

where, y is assumed as a normal distribution centered by its mean and
variance.

Additionally, the parameters in the model are generated from a
probability distribution. The posterior probability of these parameters
is proportional to the prior and likelihood [@minka2000bayesian].

$$
P(\beta|y, X) = \frac{P(y|\beta, X) × P(\beta|X)}{P(y|X)}  \quad(4)
$$

::: notes
In linear regression, the mean is calculated by the transpose of the
weight matrix and the predictor matrix. The variance is determined by
squaring the standard deviation $\sigma$ and then multiplying it by the
identity matrix.
:::

### Conjugate Distributions

In Bayesian statistics, when the prior distribution and the posterior
distribution belong to the same family of probability distributions,
they are called conjugate distributions. Using Bayes' theorem, we have
the joint posterior distribution as follows:

$$
f(\beta, \sigma^2|y,x) = \frac{f_y(y|x, \beta,\sigma^2)f(\beta|\sigma^2,m,V)f(\sigma^2|a,b)}{f_y(y)}  \quad(5)
$$

where:

-   $f_y(y|x, \beta,\sigma^2)$ is the likelihood function,

-   $f(\beta|\sigma^2,m,V)$ is the prior distribution for coefficients,

-   $f(\sigma^2|a,b)$ is the prior distribution for the error variance,
    and

-   $f_y(y)$ is the marginal likelihood.

::: notes
-   The Joint prior distribution of the coefficients $\beta$ and the
    error variance $\sigma^2$ given the data $y$ and the predictors $x$
-   the prior distribution for coefficients $\beta$ given the error
    variance $\sigma^2$, with mean vector $m$ and covariance matrix $V$
-   error variance $\sigma^2$, which is assumed to be an inverse gamma
    distribution with parameter $a$ and $b$
-   marginal likelihood is often treated as a constant
:::

### Non-conjugate distributions

A non-conjugate prior refers to a prior distribution that does not
belong to the same family of distributions as the posterior distribution
after observing data. In such cases, the posterior distribution can be
expressed as

$$
f(\beta|y, X, \sigma^2) ∝ f_y(y|X, \beta)\prod_{i=1}^{n}f(\beta_i|m_i,v_i)  \quad(6)
$$ where:

-   $f(\beta|y, X, \sigma^2)$ is the posterior distribution of
    coefficients,

-   $f_y(y|X, \beta)$ is the likelihood function, and

-   $f(\beta_i|m_i,v_i)$ is the prior distribution of each coefficient.

::: notes
-   is the posterior distribution of coefficients $\beta$ given the
    dependent variable $y$, independent variable $X$ and error variance
    $\sigma^2$.
-   likelihood function, denoting the probability of the observing data
    $y$ given independent variable $X$ and the coefficient parameters
    $\beta$
-   the prior distribution of each coefficient $\beta_i$ with mean $m_i$
    and variance $v_i$
:::
:::

# Analysis

## Necessary packages required

```{r}
#| echo: True
#| eval: true
library(tidyverse)
library(gtsummary)
library(skimr)
library(randomForest)
library(GGally)
library(corrplot)
library(car)
library(ggrepel)
library(rstan)
library(rstanarm)
library(bayesplot)
```

## Dataset Introduction {.smaller}

The selected Life Expectancy dataset comprises of 21 health, economic,
and social factors taken from 179 countries between years 2000 and 2015.

::: panel-tabset
### Code

```{r}
#| echo: True
#| eval: false
# Read CSV file directly from a website URL

url = "C:/Users/shiji/OneDrive/桌面/STA6257_capstone/Life-Expectancy-Data-Updated.csv"
ledata = read.csv(url, header = TRUE)

names(ledata) <- c("Country", 'Region',"Year", "InfDth","UnFiveDths","AdultMort", "Alcohol","HepB","Measles","BMI","Polio", "Diphtheria", "HIV", "GDP", "population","ThinAd","ThinChild","Schooling",'Developing','Developed', "LifeExp")
str(ledata)
```

### Output

```{r}
#| echo: false
#| eval: true
# Read CSV file directly from a website URL

url = "C:/Users/shiji/OneDrive/桌面/STA6257_capstone/Life-Expectancy-Data-Updated.csv"
ledata = read.csv(url, header = TRUE)

names(ledata) <- c("Country", 'Region',"Year", "InfDth","UnFiveDths","AdultMort", "Alcohol","HepB","Measles","BMI","Polio", "Diphtheria", "HIV", "GDP", "population","ThinAd","ThinChild","Schooling",'Developing','Developed', "LifeExp")
str(ledata)
```

### Description

![](images/Data%20introduction-01.png)
:::

## Exploration Data Analysis {.smaller}

Let's look at the distribution of life expectancy and the discrepancies
of life expectancy in all regions over the years.

::: panel-tabset
### Code

```{r}
#| echo: true
#| eval: false

# Distribution of Life Expectancy (years)

hist(ledata$LifeExp, 
     main = "Distribution of Life Expectancy (years)",
     xlab = "Life Expectancy",
     border = "white", 
     col = "lightblue",
     ylim = c(0, 800))

# Create a line plot for max, mean, and min life expectancy in all regions over the years
life_expectancy_summary <- ledata %>%
  group_by(Year, Region) %>%
  summarise(
    mean_life_expectancy = mean(LifeExp) )
ggplot(life_expectancy_summary, aes(x = Year)) +
  geom_line(aes(y = mean_life_expectancy, color = Region), linetype = "solid") +
  labs(title = "Regional Life Expectancy by Year (years)", x = "Year", y = "Life Expectancy", color = "Region") +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") 

# Life Expectancy by Economy Status and Region
ggplot(ledata, aes(x = factor(Developing), y = LifeExp, fill = factor(Developed))) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge", color = "black", width = 0.7) +
  labs(title = "Life Expectancy by Economy Status and Region", x = "Economy Status", y = "Mean Life Expectancy") +
  scale_fill_manual(values = c("skyblue", "salmon"), labels = c("Developing", "Developed")) +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  facet_wrap(~ Region)
```

### Output 1

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
# Distribution of Life Expectancy (years)

hist(ledata$LifeExp, 
     main = "Distribution of Life Expectancy (years)",
     xlab = "Life Expectancy",
     border = "white", 
     col = "lightblue",
     ylim = c(0, 800))
```

### Output 2

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
# Create a line plot for max, mean, and min life expectancy in all regions over the years
life_expectancy_summary <- ledata %>%
  group_by(Year, Region) %>%
  summarise(
    mean_life_expectancy = mean(LifeExp) )
ggplot(life_expectancy_summary, aes(x = Year)) +
  geom_line(aes(y = mean_life_expectancy, color = Region), linetype = "solid") +
  labs(title = "Regional Life Expectancy by Year (years)", x = "Year", y = "Life Expectancy", color = "Region") +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") 
```

### Output 3

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
# Life Expectancy by Economy Status and Region
ggplot(ledata, aes(x = factor(Developing), y = LifeExp, fill = factor(Developing))) +
  geom_bar(stat = "summary", fun = "mean", position = "dodge", color = "black", width = 0.7) +
  labs(title = "Life Expectancy by Economy Status and Region", x = "Economy Status", y = "Mean Life Expectancy") +
  scale_fill_manual(values = c("skyblue", "salmon"), labels = c("Developing", "Developed")) +
  theme_minimal() +
  theme(legend.title = element_blank()) +
  facet_wrap(~ Region) 
```

:::

##  {.smaller}

What is the impact of schooling on the lifespan of humans?

```{r}
#| echo: false
#| eval: true
#| layout-ncol: 2
#| fig-height: 5
#| fig-width: 6
# Life Expectancy versus Formal Education, 2000-2015 (years)
ledata %>% ggplot(aes(x = Schooling, y = LifeExp)) + 
  geom_point(size = 0.8, color = 'green') +
  geom_smooth()+
  theme_bw()+ 
  xlab('Average Schooling Year') +
  labs(title = 'Life Expectancy versus Formal Education, 2000-2015 (years)')+ theme(plot.title = element_text(size = 8))

# Life Expectancy versus Formal Education, by Region
ledata %>% select(Region, Schooling, LifeExp) %>%
 group_by(Region) %>%
  summarise(Avg_Schooling = mean(Schooling),
            Avg_LifeExp = mean(LifeExp)) %>%
  ggplot(aes(x = Avg_Schooling, y = Avg_LifeExp)) +
  geom_point(size = 2.5, color = 'blue', alpha = 0.5) +
  theme_bw() +
  geom_text_repel(aes(label = Region), size = 3) +
  labs(title = 'Life Expectancy versus Formal Education, by Region')+ theme(plot.title = element_text(size = 8))
```

##  {.smaller}

How does Infant and Adult mortality rates affect life expectancy?

```{r}
#| echo: false
#| eval: true
#| layout-ncol: 2
#| fig-width: 9
#| fig-height: 5

# Life Expectancy versus Infant Deaths, per 1000 population
ledata %>% select(Region,InfDth, AdultMort, LifeExp) %>%
  ggplot(aes(x = InfDth, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  labs(title = 'Life Expectancy versus Infant Deaths, per 1000 population')

# Life Expectancy versus Adult Mortality, per 1000 population
ledata %>% select(InfDth, AdultMort, LifeExp) %>%
  ggplot(aes(x = AdultMort, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  labs(title = 'Life Expectancy versus Adult Mortality, per 1000 population')

# Life Expectancy versus Children Deaths under 5 Years of Age, per 1000 population
ledata %>% 
  ggplot(aes(x = UnFiveDths, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  labs(title = 'Life Expectancy versus Children Deaths under 5 Years of Age, per 1000 population')
```

##  {.smaller}

Let's continue visualizing data. :)

Does Life Expectancy has positive or negative correlation with
Diphtheria Immunization coverage, GDP, Body Mass Index etc.?

::: panel-tabset
### DTP3

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
ledata %>% 
  ggplot(aes(x = Diphtheria, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  geom_smooth() +
  labs(title = 'Life Expectancy versus DTP3 immunization coverage among 1-year-olds (%)') + 
  xlab('DTP3 immunization rate')
```

### GDP

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
ledata %>% 
  ggplot(aes(x = GDP, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  geom_smooth() +
  labs(title = 'Life Expectancy versus GDP (USD)')
```

### BMI

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
ledata %>% 
  ggplot(aes(x = BMI, y = LifeExp)) + 
  geom_point(size = 0.5, color = 'orange') +
  theme_bw() +
  geom_smooth(method = lm) +
  labs(title = 'Life Expectancy versus Body Mass Index (BMI) of adults
')
```
:::

##  {.smaller}

Finally, let's see how much these predictors are related to lifespan and
the intercorrelations among two or more predictors.

::: panel-tabset
### Correlation

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
# Checking the correlation between those continuous variables and life expectancy.
# Remove these categorical variables from dataset.
ledata_continuous <- ledata %>% select(-c('Country', 'Region', 'Year', 'Developing', 'Developed'))
# Visualize correlation matrix

ggcorrplot::ggcorrplot(round(cor(ledata_continuous),2), type = 'lower', title = 'Correlation within the lIfe Expectancy dataset', show.legend = TRUE, lab = TRUE, lab_size = 2)
```

### Multicollinearity

```{r}
#| echo: false
#| eval: true
#| fig-width: 9
#| fig-height: 4
# Build a ordinary linear model for subsequent vif check
olr <- lm(LifeExp ~., data = ledata_continuous)

# Check Multicollinearity using vif()
vif(olr)

# Extract selected variables for subsequent BLR analysis
BLR_data <- ledata_continuous %>% select(c(GDP, BMI, Alcohol, Schooling, HIV,LifeExp))
```

Given the results of correlation and multicollinearity checking, we select the independent variables of GDP, BMI, alcohol, schooling and HIV and dependent variable
of life expectancy to contribute to our final data set used for BLR analysis.
:::

## Bayesian Linear Regression Analysis {.smaller}

-   Create a BLR model

-   Evaluate the performance of BLR model

-   Compare with Frenquentist method

## Create a BLR model {.smaller}

::: panel-tabset
### Observations & Analysis

Our dataset comprises 2,864 observations, consisting of five predictors
and one response variable.

In this analysis, we employ the **stan_glm()** function from the
**rstan** package to establish a Bayesian Linear Regression model.

### BLR Model

```{r}
# BLR model
glm_post1 <- stan_glm(LifeExp~., data=BLR_data, family=gaussian, seed = 1234)
```

### Model Results

::: columns
::: {.column width="35%"}
```{r}
glm_post1
```
:::

::: {.column width="65%"}
Upon reviewing the summary, we discern parameter estimates for the
model. Notably, the model's equation can be represented as follows:

$$LifeExp =$$

$$37.5 + 0.9×BMI + 1.2×Schooling - 1.6×HIV $$
:::
:::
:::

## Evaluate the BLR Model {.smaller}

::: panel-tabset
### Observations & Analysis

The **stan_trace()** was used to visualize the traces of parameters
estimated by Markov chain Monte Carlo (MCMC) sampling.

Each trace plot to each variable appears centered around one value and
all chains are well overlapping around one value.

### Trace Plot

```{r}
# Assess the convergence of the MCMC chains and the behavior of the parameters during sampling

stan_trace(glm_post1, pars=c("(Intercept)", "Alcohol","GDP", "BMI",  "Schooling", "HIV","sigma")) + labs(title = 'Figure 14. Trace Plots of Each Variable')
```

### Checking $\hat{R}$

::: columns
::: {.column width="35%"}
```{r}
# Checking R hat.
summary(glm_post1)
```
:::

::: {.column width="65%"}
$\hat{R}$ compares the variability in sampled parameter estimates across
all chains combined with the variability within each individual change.

$R = 1$ shows stability across chains.
:::
:::
:::

## Evaluate the BLR Model {.smaller}

The dark blue line shows the observed data while the light blue lines
are simulations from the posterior predictive distribution.

::: columns
::: {.column width="65%"}
```{r}
# look at posterior predictive checks.
pp_check(glm_post1) 
```
:::

::: {.column width="35%"}
Although the peaks of both the observed data distribution and the
posterior distribution align along the x-axis, there's a notable
discrepancy in the density values along the y-axis.
:::
:::

## Evaluate the BLR Model {.smaller}

::: panel-tabset
### Histograms

The histograms exhibit the distribution of posterior samples obtained
from the model.

```{r}
# View histogram of each parameter
stan_hist(glm_post1, pars=c("(Intercept)","Alcohol", "GDP", "BMI", "Schooling", "HIV","sigma"), bins=40)
```

### Median & Mean

In order to calculate the mean and median values of each parameter,
we extracted posterior samples from the model and converted to a data
frame .

```{r}
# Extract posterior samples
post_samps <- as.data.frame(glm_post1, pars=c("(Intercept)","Alcohol", "GDP", "BMI",  "Schooling", "HIV","sigma"))
```

Mean calculations

```{r}
# calculate the median and mean of each parameter
round(apply(post_samps, 2, mean),5)
```

Median calculations

```{r}
round(apply(post_samps, 2, median),5)
```

### Analysis of Estimates

We analyzed how the observed data has changed the parameter estimates.

```{r}
# To see how the observed data has changed the parameter estimates
posterior_vs_prior(glm_post1, group_by_parameter = TRUE, pars=c("(Intercept)", "GDP", "BMI","Alcohol",   "Schooling", "HIV","sigma"))
```

### Default Priors

```{r}
# Checking default priors
prior_summary(glm_post1)
```
:::

## Compare with Frenquentist Method {.smaller}

::: panel-tabset
### Frenquentist Model

Resulting Model $LifeExp = 37.5 + 0.9×BMI + 1.2×Schooling + -1.6×HIV$.

```{r}
# Establish an Ordinary Linear Model
glm_fit <- glm(LifeExp~., data=BLR_data, family=gaussian)
summary(glm_fit)
```

### Comparison of Models {.smaller}

The maximum likelihood estimates of the intercept and slopes are nearly
identical to the mean values of posterior samples obtained from Bayesian
Linear Regression.

Bayesian Linear Regression

```{r}
# calculate the median and mean of each parameter
round(apply(post_samps, 2, mean),5)
```

Frenquentist method

```{r}
round(glm_fit$coefficients, 5)
```
:::

# Conclusion

## Notable Observations {.smaller}

In this project, we successfully explored the effects of the predictors
on Life expectancy and relationships among them. There were some notable
observations while conducting our analysis.

-   There was a significant negative relationship between adult
    mortality, infants deaths, deaths under five years old, and life
    expectancy. As the rates of death of adults, infants, and children
    under 5 years old go up, life expectancy tends to shorten.

-   The rates of thinness of adolescents and adults are also critical
    factors affecting life expectancy, and there is a negative
    relationship existing between them.

-   Life expectancy varies depending on the disparity in years of
    schooling across regions. Generally, life expectancy tends to rise
    with increase of schooling and higher level of economy development
    since 2000.

-   Due to the presence of correlation and multicollinearity, we
    selected only five variables as predictors for conducting Bayesian
    Linear Regression Analysis.

## Bayesian Linear Regression Analysis Conclusion {.smaller}

-   Our model is a perfect fit to the dataset of life expectancy when
    considering the variables of GDP, BMI, Alcohol, schooling and HIV.

-   The convergence of four chains is strong, and it's centered around a
    single value, indicating the excellent performance of the model.

-   Through observing the BLR model, the variables of BMI, Schooling,
    and HIV have more weight on predicting life expectancy.

# Questions?
